{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waWeJeoCeezg",
        "outputId": "76a0dd6b-aa3c-41ff-b10c-e2e18ed9bab6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycuda\n",
            "  Downloading pycuda-2024.1.tar.gz (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytools>=2011.2 (from pycuda)\n",
            "  Downloading pytools-2024.1.3-py2.py3-none-any.whl (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.4/87.4 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting appdirs>=1.4.0 (from pycuda)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting mako (from pycuda)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.2.2)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.11.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from mako->pycuda) (2.1.5)\n",
            "Building wheels for collected packages: pycuda\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2024.1-cp310-cp310-linux_x86_64.whl size=661204 sha256=fcd9e762ca21b48af58f45b67d5b68ce45061ef2b08ac4d78665b2a089770f6a\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/34/d2/9a349255a4eca3a486d82c79d21e138ce2ccd90f414d9d72b8\n",
            "Successfully built pycuda\n",
            "Installing collected packages: appdirs, pytools, mako, pycuda\n",
            "Successfully installed appdirs-1.4.4 mako-1.3.5 pycuda-2024.1 pytools-2024.1.3\n"
          ]
        }
      ],
      "source": [
        "!pip install pycuda"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile hello_world_pycuda.py\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "import numpy as np\n",
        "\n",
        "# CUDA kernel code to return data\n",
        "cuda_code = \"\"\"\n",
        "__global__ void return_data(char *output) {\n",
        "    const char msg[] = \"Hello, World!\";\n",
        "    int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    if (idx < sizeof(msg)) {\n",
        "        output[idx] = msg[idx];\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Compile the CUDA module\n",
        "cuda_module = SourceModule(cuda_code)\n",
        "return_data_kernel = cuda_module.get_function(\"return_data\")\n",
        "\n",
        "#Allocate memory on the GPU for the output\n",
        "output_size = 15 # Length of the \"Hello, World!\" string + null terminator\n",
        "output_gpu = cuda.mem_alloc(output_size)\n",
        "\n",
        "# Set up block and grid dimensions\n",
        "block_dim = (output_size, 1, 1)\n",
        "grid_dim = (1, 1)\n",
        "\n",
        "# Launch the kernel\n",
        "return_data_kernel(output_gpu, block=block_dim, grid=grid_dim)\n",
        "\n",
        "# Copy the result back to the host\n",
        "output_host = np.empty(output_size, dtype=np.uint8)\n",
        "cuda.memcpy_dtoh(output_host, output_gpu)\n",
        "\n",
        "#Convert the result to a string and print it\n",
        "output_str = ''.join(chr(c) for c in output_host)\n",
        "print(output_str)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eG9oz-VgjHh3",
        "outputId": "b2c239c1-134b-4bfc-a738-a2873d929e74"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting hello_world_pycuda.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python hello_world_pycuda.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1ZCTlkgkEf9",
        "outputId": "d8c7a852-55e9-44ad-8ee1-85280d55b4ef"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, World!\u0000\u0000\n"
          ]
        }
      ]
    }
  ]
}